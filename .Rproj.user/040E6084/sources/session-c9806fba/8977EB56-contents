## ----setup, include = FALSE---------------------------------------------------
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  warning = FALSE,
  message = FALSE,
  eval = FALSE
)

## -----------------------------------------------------------------------------
# library(geospatialsuite)

## -----------------------------------------------------------------------------
# # Basic syntax
# result <- spatial_join_universal(
#   vector_data = "your_points.csv",        # ANY vector data
#   raster_data = "your_raster.tif",        # ANY raster data
#   method = "simple"                       # Extraction method
# )

## -----------------------------------------------------------------------------
# # 1. CSV files with coordinates
# points_from_csv <- spatial_join_universal(
#   vector_data = "study_sites.csv",  # Auto-detects coordinate columns
#   raster_data = "elevation.tif"
# )
# 
# # 2. Shapefiles and spatial formats
# boundaries_analysis <- spatial_join_universal(
#   vector_data = "field_boundaries.shp",
#   raster_data = "ndvi_stack.tif"
# )
# 
# # 3. sf objects in memory
# sf_analysis <- spatial_join_universal(
#   vector_data = my_sf_object,
#   raster_data = raster_list
# )
# 
# # 4. Data frames with custom coordinate columns
# df_analysis <- spatial_join_universal(
#   vector_data = monitoring_data,
#   raster_data = "satellite_imagery/",
#   coord_cols = c("longitude", "latitude")
# )

## -----------------------------------------------------------------------------
# # 1. Single raster file
# single_raster <- spatial_join_universal(
#   vector_data = sites,
#   raster_data = "elevation.tif"
# )
# 
# # 2. Multiple raster files
# multi_raster <- spatial_join_universal(
#   vector_data = sites,
#   raster_data = c("ndvi.tif", "soil_ph.tif", "precipitation.tif")
# )
# 
# # 3. Directory of raster files
# directory_rasters <- spatial_join_universal(
#   vector_data = sites,
#   raster_data = "satellite_imagery/"  # All .tif files in directory
# )
# 
# # 4. List of raster objects
# raster_objects <- spatial_join_universal(
#   vector_data = sites,
#   raster_data = list(elevation_raster, slope_raster, aspect_raster)
# )

## -----------------------------------------------------------------------------
# # Direct extraction at point/polygon locations
# simple_extraction <- spatial_join_universal(
#   vector_data = field_sites,
#   raster_data = "soil_nitrogen.tif",
#   method = "simple"
# )

## -----------------------------------------------------------------------------
# # Create buffers around features and extract within buffer
# buffer_extraction <- spatial_join_universal(
#   vector_data = monitoring_stations,
#   raster_data = "land_cover.tif",
#   method = "buffer",
#   buffer_size = 1000,  # 1km buffer
#   summary_function = "mean"
# )
# 
# # Different summary functions
# median_buffer <- spatial_join_universal(
#   vector_data = study_plots,
#   raster_data = "biomass.tif",
#   method = "buffer",
#   buffer_size = 500,
#   summary_function = "median"
# )

## -----------------------------------------------------------------------------
# # Best for continuous data and point locations
# bilinear_extraction <- spatial_join_universal(
#   vector_data = weather_stations,
#   raster_data = "temperature.tif",
#   method = "bilinear"
# )

## -----------------------------------------------------------------------------
# # Good for categorical data
# nearest_extraction <- spatial_join_universal(
#   vector_data = sample_points,
#   raster_data = "land_use_classification.tif",
#   method = "nearest"
# )

## -----------------------------------------------------------------------------
# # Integrate multiple environmental datasets
# comprehensive_analysis <- integrate_multiple_datasets(
#   vector_data = "research_sites.csv",
#   raster_datasets = list(
#     # Vegetation data
#     ndvi = "satellite/ndvi_2023.tif",
#     evi = "satellite/evi_2023.tif",
# 
#     # Soil data
#     soil_nitrogen = "soil/nitrogen.tif",
#     soil_carbon = "soil/carbon.tif",
#     soil_ph = "soil/ph.tif",
# 
#     # Climate data
#     precipitation = "climate/annual_precip.tif",
#     temperature = "climate/mean_temp.tif",
# 
#     # Terrain data
#     elevation = "terrain/dem.tif",
#     slope = "terrain/slope.tif",
#     aspect = "terrain/aspect.tif"
#   ),
#   analysis_functions = list(
#     mean = function(x) mean(x, na.rm = TRUE),
#     median = function(x) median(x, na.rm = TRUE),
#     cv = function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
#   ),
#   extraction_method = "buffer",
#   buffer_size = 1000
# )

## -----------------------------------------------------------------------------
# # Analysis constrained to specific regions
# regional_analysis <- spatial_join_universal(
#   vector_data = field_sites,
#   raster_data = "satellite_time_series/",
#   region_boundary = "Ohio",  # Automatic region filtering
#   method = "buffer",
#   buffer_size = 500
# )
# 
# # Custom bounding box
# bbox_analysis <- spatial_join_universal(
#   vector_data = study_points,
#   raster_data = "climate_data/",
#   region_boundary = c(-84.5, 39.0, -82.0, 41.0),  # xmin, ymin, xmax, ymax
#   method = "simple"
# )

## -----------------------------------------------------------------------------
# # Monitoring stations with multi-scale analysis
# station_analysis <- extract_to_points_advanced(
#   points_data = "water_monitoring_stations.csv",
#   raster_data = "land_cover.tif",
#   sampling_strategy = "multi_scale",
#   buffer_sizes = c(100, 500, 1000, 2000),
#   summary_functions = list(
#     mode = function(x) names(sort(table(x), decreasing = TRUE))[1],
#     diversity = function(x) length(unique(x[!is.na(x)]))
#   )
# )

## -----------------------------------------------------------------------------
# # Agricultural field analysis
# field_analysis <- spatial_join_universal(
#   vector_data = "agricultural_fields.shp",
#   raster_data = "crop_yield_map.tif",
#   method = "simple",  # Extracts all pixels within polygons
#   summary_function = "mean"
# )
# 
# # Watershed analysis
# watershed_analysis <- spatial_join_universal(
#   vector_data = "watersheds.shp",
#   raster_data = list(
#     precipitation = "precip.tif",
#     temperature = "temp.tif",
#     vegetation = "ndvi.tif"
#   ),
#   method = "simple",
#   summary_function = "mean"
# )

## -----------------------------------------------------------------------------
# # Stream network analysis
# stream_analysis <- spatial_join_universal(
#   vector_data = "stream_network.shp",
#   raster_data = "water_quality_interpolated.tif",
#   method = "buffer",
#   buffer_size = 100,  # 100m buffer around streams
#   summary_function = "mean"
# )

## -----------------------------------------------------------------------------
# # Match observations with satellite data by date
# temporal_matching <- spatial_join_temporal(
#   vector_data = "field_observations.csv",  # Must have date column
#   raster_time_series = "satellite_ndvi_time_series/",
#   time_column = "observation_date",
#   time_tolerance = 7,  # 7 days tolerance
#   temporal_method = "nearest"
# )
# 
# # Window-based temporal matching
# window_matching <- spatial_join_temporal(
#   vector_data = field_data,
#   raster_time_series = ndvi_time_series,
#   time_column = "date",
#   temporal_method = "window",
#   window_days = 30  # 30-day window
# )

## -----------------------------------------------------------------------------
# # The function automatically handles:
# 
# # 1. Coordinate system mismatches
# mixed_crs_analysis <- spatial_join_universal(
#   vector_data = "sites_utm.shp",      # UTM projection
#   raster_data = "satellite_wgs84.tif"  # Geographic projection
#   # Automatic reprojection applied
# )
# 
# # 2. Missing coordinate columns
# auto_coord_detection <- spatial_join_universal(
#   vector_data = "stations.csv",  # Auto-detects lon/lat, x/y, etc.
#   raster_data = "climate.tif"
# )
# 
# # 3. Invalid geometries
# invalid_geom_handling <- spatial_join_universal(
#   vector_data = problematic_shapefile,  # Automatically fixes invalid geometries
#   raster_data = analysis_raster
# )
# 
# # 4. Spatial non-overlap
# non_overlap_handling <- spatial_join_universal(
#   vector_data = distant_points,
#   raster_data = local_raster
#   # Returns NAs with informative warnings
# )

## -----------------------------------------------------------------------------
# # Comprehensive validation during processing
# validated_analysis <- spatial_join_universal(
#   vector_data = field_sites,
#   raster_data = "satellite_data.tif",
#   method = "buffer",
#   buffer_size = 1000,
#   verbose = TRUE  # Detailed progress and validation messages
# )

## -----------------------------------------------------------------------------
# # Optimized for large datasets
# large_analysis <- spatial_join_universal(
#   vector_data = "10000_sample_points.csv",
#   raster_data = "very_large_raster.tif",
#   method = "simple",
#   progress_interval = 100,  # Progress every 100 features
#   verbose = TRUE
# )
# 
# # Parallel processing for multiple rasters
# parallel_analysis <- integrate_multiple_datasets(
#   vector_data = study_sites,
#   raster_datasets = many_raster_files,
#   parallel = TRUE,
#   extraction_method = "buffer",
#   buffer_size = 500
# )

## -----------------------------------------------------------------------------
# # Efficient memory usage
# memory_efficient <- spatial_join_universal(
#   vector_data = large_polygon_dataset,
#   raster_data = high_resolution_raster,
#   method = "simple",
#   na_rm = TRUE,  # Remove NAs during processing
#   summary_function = "mean"
# )

## -----------------------------------------------------------------------------
# # Comprehensive farm analysis
# farm_analysis <- integrate_multiple_datasets(
#   vector_data = "farm_fields.shp",
#   raster_datasets = list(
#     ndvi = "satellite/ndvi.tif",
#     soil_nitrogen = "soil/nitrogen.tif",
#     yield = "yield_monitor/yield.tif",
#     elevation = "terrain/dem.tif"
#   ),
#   analysis_functions = list(
#     field_mean = function(x) mean(x, na.rm = TRUE),
#     field_cv = function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE),
#     field_max = function(x) max(x, na.rm = TRUE)
#   )
# )

## -----------------------------------------------------------------------------
# # Multi-parameter environmental assessment
# environmental_analysis <- integrate_multiple_datasets(
#   vector_data = "monitoring_stations.csv",
#   raster_datasets = list(
#     air_quality = "air_quality/pm25.tif",
#     noise_pollution = "noise/noise_levels.tif",
#     green_space = "landcover/green_space.tif",
#     population_density = "demographics/population.tif"
#   ),
#   extraction_method = "buffer",
#   buffer_size = 2000,  # 2km around each station
#   region_boundary = "urban_area.shp"
# )

## -----------------------------------------------------------------------------
# # Biodiversity habitat analysis
# habitat_analysis <- spatial_join_universal(
#   vector_data = "species_observations.csv",
#   raster_data = list(
#     vegetation_height = "lidar/height.tif",
#     canopy_cover = "remote_sensing/canopy.tif",
#     water_distance = "hydrology/water_dist.tif",
#     human_disturbance = "infrastructure/disturbance.tif"
#   ),
#   method = "buffer",
#   buffer_size = 500,
#   summary_function = "mean"
# )

## -----------------------------------------------------------------------------
# # Ensure data quality before analysis
# cleaned_data <- process_vector_data(
#   "raw_field_data.csv",
#   coord_cols = c("longitude", "latitude"),
#   crs_code = 4326,
#   verbose = TRUE
# )
# 
# # Validate raster data
# raster_list <- load_raster_data(
#   "satellite_imagery/",
#   pattern = "\\.(tif|tiff)$",
#   verbose = TRUE
# )

## -----------------------------------------------------------------------------
# # Choose appropriate extraction method based on:
# 
# # Point data + continuous raster → bilinear
# weather_interpolation <- spatial_join_universal(
#   vector_data = weather_stations,
#   raster_data = temperature_surface,
#   method = "bilinear"
# )
# 
# # Point data + categorical raster → nearest
# landuse_extraction <- spatial_join_universal(
#   vector_data = sample_points,
#   raster_data = landuse_classification,
#   method = "nearest"
# )
# 
# # Any data + need local context → buffer
# contextual_analysis <- spatial_join_universal(
#   vector_data = study_sites,
#   raster_data = environmental_layers,
#   method = "buffer",
#   buffer_size = 1000
# )

## -----------------------------------------------------------------------------
# # Always validate results
# result_validation <- function(spatial_join_result) {
#   # Check for completeness
#   completeness <- sum(!is.na(spatial_join_result$extracted_variable)) /
#                   nrow(spatial_join_result)
# 
#   cat("Data completeness:", round(completeness * 100, 1), "%\n")
# 
#   # Check value ranges
#   value_range <- range(spatial_join_result$extracted_variable, na.rm = TRUE)
#   cat("Value range:", value_range[1], "to", value_range[2], "\n")
# 
#   return(spatial_join_result)
# }
# 
# # Apply validation
# validated_results <- result_validation(analysis_results)

